{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Engineering with Weave\n",
    "\n",
    "This notebook demonstrates the prompt engineering capabilities of the Weave framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from weave.prompts import PromptTemplate, PromptLibrary, PromptOptimizer\n",
    "from weave.llms import OpenAILLM\n",
    "\n",
    "# Initialize LLM\n",
    "llm = OpenAILLM(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    api_key=\"your-api-key\"  # or use environment variable\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Working with Prompt Templates\n",
    "\n",
    "Create and use dynamic prompt templates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a template\n",
    "template = PromptTemplate(\n",
    "    \"Classify the sentiment of this $language text: $text\",\n",
    "    metadata={\"task\": \"sentiment_analysis\", \"version\": \"1.0\"}\n",
    ")\n",
    "\n",
    "# Render template\n",
    "prompt = template.render({\n",
    "    \"language\": \"English\",\n",
    "    \"text\": \"This product is amazing!\"\n",
    "})\n",
    "\n",
    "print(f\"Rendered prompt: {prompt}\")\n",
    "print(f\"Template metadata: {template.get_metadata()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Using the Prompt Library\n",
    "\n",
    "Work with pre-defined prompt templates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create library\n",
    "library = PromptLibrary()\n",
    "\n",
    "# Add custom template\n",
    "qa_template = PromptTemplate(\n",
    "    \"Answer the question based on the context:\\n\\n\"\n",
    "    \"Context: $context\\n\\n\"\n",
    "    \"Question: $question\",\n",
    "    metadata={\"task\": \"question_answering\"}\n",
    ")\n",
    "\n",
    "library.add_template(\"qa\", qa_template, category=\"specialized\")\n",
    "\n",
    "# List available templates\n",
    "print(\"Available categories:\")\n",
    "for category in library.get_categories():\n",
    "    templates = library.get_templates_in_category(category)\n",
    "    print(f\"{category}: {templates}\")\n",
    "\n",
    "# Use a template\n",
    "template = library.get_template(\"qa\")\n",
    "prompt = template.render({\n",
    "    \"context\": \"The cat sat on the mat.\",\n",
    "    \"question\": \"Where did the cat sit?\"\n",
    "})\n",
    "\n",
    "print(f\"\\nRendered QA prompt: {prompt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prompt Optimization\n",
    "\n",
    "Optimize prompts using feedback loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create optimizer\n",
    "optimizer = PromptOptimizer(\n",
    "    model_connector=llm,\n",
    "    optimization_config={\n",
    "        \"max_tokens\": 150,\n",
    "        \"temperature\": 0.7\n",
    "    }\n",
    ")\n",
    "\n",
    "# Define test cases\n",
    "test_cases = [\n",
    "    {\n",
    "        \"input\": {\n",
    "            \"text\": \"This movie was fantastic!\",\n",
    "            \"categories\": \"positive, negative, neutral\"\n",
    "        },\n",
    "        \"expected\": \"positive\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": {\n",
    "            \"text\": \"I didn't enjoy this book at all.\",\n",
    "            \"categories\": \"positive, negative, neutral\"\n",
    "        },\n",
    "        \"expected\": \"negative\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Define evaluation function\n",
    "def evaluate_classification(response: str, expected: str) -> float:\n",
    "    return 1.0 if response.strip().lower() == expected.lower() else 0.0\n",
    "\n",
    "# Get template from library\n",
    "template = library.get_template(\"classification\")\n",
    "\n",
    "# Optimize template\n",
    "optimized = optimizer.optimize(\n",
    "    template=template,\n",
    "    test_cases=test_cases,\n",
    "    evaluation_fn=evaluate_classification,\n",
    "    num_iterations=3\n",
    ")\n",
    "\n",
    "print(\"Optimization history:\")\n",
    "for record in optimizer.get_optimization_history():\n",
    "    print(f\"Iteration {record['iteration']}: {record['score']}\")\n",
    "\n",
    "print(f\"\\nBest template:\\n{optimized.template.template}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Multi-Turn Prompts\n",
    "\n",
    "Create conversation-style prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create conversation template\n",
    "conversation_template = PromptTemplate(\n",
    "    \"\"\"Previous conversation:\n",
    "$history\n",
    "\n",
    "User: $user_input\n",
    "Assistant: Let me help you with that.\"\"\"\n",
    ")\n",
    "\n",
    "# Build conversation history\n",
    "history = [\n",
    "    {\"role\": \"user\", \"content\": \"Hello!\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Hi! How can I help you today?\"},\n",
    "    {\"role\": \"user\", \"content\": \"I need help with my code.\"}\n",
    "]\n",
    "\n",
    "# Format history\n",
    "formatted_history = \"\\n\".join(\n",
    "    f\"{turn['role'].title()}: {turn['content']}\"\n",
    "    for turn in history\n",
    ")\n",
    "\n",
    "# Render template\n",
    "prompt = conversation_template.render({\n",
    "    \"history\": formatted_history,\n",
    "    \"user_input\": \"Can you explain how to use functions?\"\n",
    "})\n",
    "\n",
    "print(\"Multi-turn prompt:\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Saving and Loading Templates\n",
    "\n",
    "Persist templates and optimization results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "# Save template to file\n",
    "with tempfile.TemporaryDirectory() as temp_dir:\n",
    "    template_path = Path(temp_dir) / \"template.json\"\n",
    "    template.to_file(template_path)\n",
    "    \n",
    "    # Load template from file\n",
    "    loaded_template = PromptTemplate.from_file(template_path)\n",
    "    print(f\"Loaded template: {loaded_template.template.template}\")\n",
    "    \n",
    "    # Save entire library\n",
    "    library_dir = Path(temp_dir) / \"templates\"\n",
    "    library.save_to_directory(library_dir)\n",
    "    \n",
    "    # Load library from directory\n",
    "    loaded_library = PromptLibrary.from_directory(library_dir)\n",
    "    print(f\"\\nLoaded library categories: {loaded_library.get_categories()}\")\n",
    "    \n",
    "    # Save optimization history\n",
    "    history_path = Path(temp_dir) / \"optimization_history.json\"\n",
    "    optimizer.save_history(history_path)\n",
    "    \n",
    "    # Load optimization history\n",
    "    new_optimizer = PromptOptimizer(model_connector=llm)\n",
    "    new_optimizer.load_history(history_path)\n",
    "    print(f\"\\nLoaded optimization records: {len(new_optimizer.get_optimization_history())}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
